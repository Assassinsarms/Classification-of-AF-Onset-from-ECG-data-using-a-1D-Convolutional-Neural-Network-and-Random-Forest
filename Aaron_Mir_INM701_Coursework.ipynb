{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.1 64-bit",
   "display_name": "Python 3.8.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# INM701 Coursework\n",
    "### Aaron Mir (Student Number: 160001207)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In this coursework, you are expected to demonstrate what you have learned in the module by applying artificial intelligence techniques as covered in the module to a dataset and domain of your choice. This will include some or all of:\n",
    "\n",
    "    • Define the domain and dataset(s) (you are free to choose the domain and the dataset that you want to investigate).\n",
    "\n",
    "    • Define  questions and analysis tasks (a brief overview  of  the  domain, analytical questions that are being asked, a list of your objectives and the \n",
    "    expected output(s)of your analysis)\n",
    "    \n",
    "    • Perform an initial investigation of the dataset and the characteristics of the data. Develop a viable plan: which  data  processing  steps  you  will  need  to\n",
    "    perform, how you will transform the data to make it useable, which artificial intelligence techniques you can potentially use and what sorts of potential\n",
    "    observations these can lead to.\n",
    "\n",
    "    • Perform the analysis.  Get the data ready for analysis, carry out your analysis/modelling as  needed,  validate your  results  and  communicate observations, \n",
    "    iterating through this process. Analytical operations can include data processing to an extent that is needed (not all datasets are messy) to prepare a useful and\n",
    "    robust dataset to work within, and data derivation (such as feature engineering).\n",
    "\n",
    "    • Split your dataset (train/validate/test, somedatasets come pre-split). If you have a holdout test set then you most likely don’t want to use this until the near \n",
    "    the end of your work.\n",
    "\n",
    "    • You might establish a baseline result first, computing metrics on training and validation sets,  analyse  errors, work  on  succeeding iterations, and \n",
    "    alternative models. (If initial metrics are amazing and there are no errors is the problem too easy?)\n",
    "\n",
    "    • Be  close to your data  (visualise  the  dataset,  collect  summary  statistics,  look  at  errors, analyse how different parameters affect performance, try \n",
    "    out different model variants).\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import copy\n"
   ]
  }
 ]
}